{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook contains all the methods used for prediction NSCLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contact: \n",
    "\n",
    "Saransh Gupta: saransh.official.iitkgp@gmail.com\n",
    "\n",
    "Website: http://saranshqm.github.io/\n",
    "\n",
    "Merge files to : https://github.com/saranshqm/NIBIOHN-NSCLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEPT4 was present already\n",
      "SEPT4 was present already\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('file:///D:/remote%20projects/NIBIOHN/NSCLC/training%20files/non_oversampled_data/original_data_with_412_genes.csv')\n",
    "train = train.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "\n",
    "try:\n",
    "    train['SEPT4']\n",
    "\n",
    "except:\n",
    "    train.rename(columns={'Sep-04': 'SEPT4'}, inplace=True)\n",
    "else:\n",
    "    print('SEPT4 was present already')\n",
    "    \n",
    "    \n",
    "    \n",
    "test = pd.read_csv('file:///D:/remote%20projects/NIBIOHN/NSCLC/test%20files/test_after_features_selection.csv')\n",
    "test = test.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "try:\n",
    "    test['SEPT4']\n",
    "\n",
    "except:\n",
    "    test.rename(columns={'Sep-04': 'SEPT4'}, inplace=True)\n",
    "else:\n",
    "    print('SEPT4 was present already')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.columns\n",
    "\n",
    "# for i in a:\n",
    "#     print(i)\n",
    "import random\n",
    "random.seed(2)\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier removal(using Z-test) ----> oversampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(train))\n",
    "threshold = 3\n",
    "original_train = train\n",
    "train = train[(z < 3).all(axis=1)]\n",
    "train.columns\n",
    "y = train['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x = train[train.columns[:-1]]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state = 2)\n",
    "# sm = SMOTE(random_state = 2) \n",
    "# x, y = sm.fit_sample(x, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 412)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak Classifiers\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Trees Classifiers\n",
    "3. Support Vector Machines\n",
    "4. Deep Neural Networks (sequential modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression  \n",
    "\n",
    "params: C=0.05827593122724494,penalty='l1', solver='liblinear',\n",
    "                                      tol=0.01, max_iter=10,\n",
    "                                      warm_start=True,\n",
    "                                      intercept_scaling=10,random_state = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and checking cross-validation scores\n",
      "\n",
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  0.9672131147540983  Val AUC-ROC score:  0.9606731775374956 \n",
      "\n",
      "validation kappa:- 0.8865581473401577\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  0.9774590163934427  Val AUC-ROC score:  0.9393965817928148 \n",
      "\n",
      "validation kappa:- 0.8563902107409925\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  0.9692622950819673  Val AUC-ROC score:  0.9565748168817578 \n",
      "\n",
      "validation kappa:- 0.8731760193446176\n",
      "Here we go with the confision Matrix\n",
      "\n",
      "[[114   8]\n",
      " [  1  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       122\n",
      "           1       0.85      0.98      0.91        47\n",
      "\n",
      "    accuracy                           0.95       169\n",
      "   macro avg       0.92      0.96      0.94       169\n",
      "weighted avg       0.95      0.95      0.95       169\n",
      "\n",
      "\n",
      "\n",
      "........................Testing the Model..............................\n",
      "\n",
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "Here we go with the confision Matrix\n",
      "\n",
      "[[191   8]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       199\n",
      "           1       0.70      1.00      0.83        19\n",
      "\n",
      "    accuracy                           0.96       218\n",
      "   macro avg       0.85      0.98      0.90       218\n",
      "weighted avg       0.97      0.96      0.97       218\n",
      "\n",
      "test kappa: \t 0.8062652743834704\n",
      "test roc score: \t 0.9798994974874372\n"
     ]
    }
   ],
   "source": [
    "print('Training and checking cross-validation scores\\n')\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=0.05827593122724494,penalty='l1', solver='liblinear',\n",
    "                                      tol=0.01, max_iter=10,\n",
    "                                      warm_start=True,\n",
    "                                      intercept_scaling=10,random_state = 2)\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y): \n",
    "     \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    #print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "#     X_train, Y_train = sm.fit_sample(x, y.ravel())\n",
    "    \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    \n",
    "    model = clf.fit(X_train,Y_train)\n",
    "    a_train = model.predict(X_train)\n",
    "    a_test = model.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "    print('validation kappa:-',cohen_kappa_score(Y_test,a_test))\n",
    "print('Here we go with the confision Matrix\\n')\n",
    "print(confusion_matrix(Y_test,a_test))\n",
    "print(classification_report(Y_test,a_test))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('........................Testing the Model..............................\\n')\n",
    "\n",
    "\n",
    "\n",
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_testt_pred = model.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.5:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "\n",
    "print('Here we go with the confision Matrix\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "\n",
    "print('test kappa: \\t',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score: \\t',roc_auc_score(y_testt,a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_KFOLD_OVERSAMPLE.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boruta_feature_selector.support_weak_ \n",
    "\n",
    "\n",
    "\n",
    "import pickle \n",
    "  \n",
    "# # Save the trained model as a pickle string. \n",
    "# saved_model = pickle.dumps(boruta_feature_selector) \n",
    "\n",
    "\n",
    "# from sklearn.externals import joblib \n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "joblib.dump(model, 'logistic_regression_KFOLD_OVERSAMPLE.pkl') \n",
    "  \n",
    "# # Load the model from the file \n",
    "# # knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# # Use the loaded model to make predictions \n",
    "# # knn_from_joblib.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees Classifiers (DTC)\n",
    "\n",
    "params: class_weight=None, criterion='gini', max_depth=int(10),\n",
    "                       max_features=int(10.4),\n",
    "                       min_samples_leaf=int(10), min_samples_split=2,\n",
    "                       random_state=42, splitter='best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  0.9590163934426229  Val AUC-ROC score:  0.8968433903034531 \n",
      "\n",
      "val kappa:- 0.7936867806069061\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  0.9651639344262294  Val AUC-ROC score:  0.8927450296477154 \n",
      "\n",
      "val kappa:- 0.7803863813566664\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  0.9426229508196722  Val AUC-ROC score:  0.8755667945587723 \n",
      "\n",
      "val kappa:- 0.7610885315426754\n",
      "[[115   7]\n",
      " [  9  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       122\n",
      "           1       0.84      0.81      0.83        47\n",
      "\n",
      "    accuracy                           0.91       169\n",
      "   macro avg       0.89      0.88      0.88       169\n",
      "weighted avg       0.90      0.91      0.90       169\n",
      "\n",
      "\n",
      "\n",
      "........................Testing the Model..............................\n",
      "\n",
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "Here we go with the confision Matrix\n",
      "\n",
      "[[193   6]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       199\n",
      "           1       0.76      1.00      0.86        19\n",
      "\n",
      "    accuracy                           0.97       218\n",
      "   macro avg       0.88      0.98      0.92       218\n",
      "weighted avg       0.98      0.97      0.97       218\n",
      "\n",
      "test kappa: \t 0.848646146725295\n",
      "test roc score: \t 0.9849246231155778\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=int(10),\n",
    "                       max_features=int(10.4),\n",
    "                       min_samples_leaf=int(10), min_samples_split=2,\n",
    "                       random_state=42, splitter='best')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "# X is the feature set and y is the target\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y): \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    #print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "    \n",
    "    model = clf.fit(X_train,Y_train)\n",
    "    a_train = model.predict(X_train)\n",
    "    a_test = model.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "\n",
    "    print('val kappa:-',cohen_kappa_score(Y_test,a_test))\n",
    "\n",
    "print(confusion_matrix(Y_test,a_test))\n",
    "print(classification_report(Y_test,a_test))\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('........................Testing the Model..............................\\n')\n",
    "\n",
    "\n",
    "\n",
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_testt_pred = model.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.5:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "\n",
    "print('Here we go with the confision Matrix\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "\n",
    "print('test kappa: \\t',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score: \\t',roc_auc_score(y_testt, a_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_trees_KFOLD_OVERSAMPLED.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "  \n",
    "# # Save the trained model as a pickle string. \n",
    "# saved_model = pickle.dumps(boruta_feature_selector) \n",
    "\n",
    "\n",
    "# from sklearn.externals import joblib \n",
    "  \n",
    "# # Save the model as a pickle in a file \n",
    "joblib.dump(model, 'decision_trees_KFOLD_OVERSAMPLED.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM)\n",
    "\n",
    "params: kernel='linear',gamma = 82, C = 1.4555047314930398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.9369550052319496 \n",
      "\n",
      "validation kappa:- 0.8682318288139999\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.918119986048134 \n",
      "\n",
      "validation kappa:- 0.8254432776725771\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.9254447157307291 \n",
      "\n",
      "validation kappa:- 0.7937850809403726\n",
      "[[109  13]\n",
      " [  2  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.94       122\n",
      "           1       0.78      0.96      0.86        47\n",
      "\n",
      "    accuracy                           0.91       169\n",
      "   macro avg       0.88      0.93      0.90       169\n",
      "weighted avg       0.92      0.91      0.91       169\n",
      "\n",
      "\n",
      "\n",
      "........................Testing the Model..............................\n",
      "\n",
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "Here we go with the confision Matrix\n",
      "\n",
      "[[162  37]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90       199\n",
      "           1       0.34      1.00      0.51        19\n",
      "\n",
      "    accuracy                           0.83       218\n",
      "   macro avg       0.67      0.91      0.70       218\n",
      "weighted avg       0.94      0.83      0.86       218\n",
      "\n",
      "test kappa: \t 0.43285051328927016\n",
      "test roc score: \t 0.907035175879397\n"
     ]
    }
   ],
   "source": [
    "clf =  SVC(probability = True, kernel='linear',gamma = 82, C = 1.4555047314930398)\n",
    "k_fold = 3\n",
    "skf = StratifiedKFold(n_splits=k_fold, random_state=42)\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y): \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    #print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "    \n",
    "    model = clf.fit(X_train,Y_train)\n",
    "    a_train = model.predict(X_train)\n",
    "    a_test = model.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "    print('validation kappa:-',cohen_kappa_score(Y_test,a_test))\n",
    "    \n",
    "\n",
    "print(confusion_matrix(Y_test,a_test))\n",
    "print(classification_report(Y_test,a_test))\n",
    "print('\\n')\n",
    "print('........................Testing the Model..............................\\n')\n",
    "\n",
    "\n",
    "\n",
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_testt_pred = model.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.5:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "\n",
    "print('Here we go with the confision Matrix\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "\n",
    "print('test kappa: \\t',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score: \\t',roc_auc_score(y_testt, a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_KFOLD_OVERSAMPLED.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'svm_KFOLD_OVERSAMPLED.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks (sequential modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strong Classifiers\n",
    "\n",
    "1. CATBOOST (GPU Powered)\n",
    "2. Random Forest\n",
    "3. XGBOOST\n",
    "4. LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CATBOOST\n",
    "\n",
    "params: loss_function= 'Logloss',iterations = 300,\n",
    "    learning_rate=.01,\n",
    "    max_depth=10, eval_metric = 'AUC',leaf_estimation_iterations = 10,task_type=\"GPU\",\n",
    "                           devices='0-6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.9475933031042901 \n",
      "\n",
      "validation kappa:- 0.883628851781718\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.9623299616323684 \n",
      "\n",
      "validation kappa:- 0.9127216388362885\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  1.0  Val AUC-ROC score:  0.9516916637600279 \n",
      "\n",
      "validation kappa:- 0.897513644633111\n"
     ]
    }
   ],
   "source": [
    "kfold = 3\n",
    "np.random.seed(2)\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "clf = CatBoostClassifier(loss_function= 'Logloss',iterations = 300,\n",
    "    learning_rate=.01,\n",
    "    max_depth=10, eval_metric = 'AUC',leaf_estimation_iterations = 10,task_type=\"GPU\",\n",
    "                           devices='0-6')\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y): \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "    \n",
    "    mdl = clf.fit(X_train,Y_train,verbose=False)\n",
    "    a_train = mdl.predict(X_train)\n",
    "    a_test = mdl.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "    print('validation kappa:-',cohen_kappa_score(Y_test,a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['catboost_KFOLD_OVERSAMPLING.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mdl, 'catboost_KFOLD_OVERSAMPLING.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118   4]\n",
      " [  3  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       122\n",
      "           1       0.92      0.94      0.93        47\n",
      "\n",
      "    accuracy                           0.96       169\n",
      "   macro avg       0.95      0.95      0.95       169\n",
      "weighted avg       0.96      0.96      0.96       169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(Y_test,a_test))\n",
    "print(classification_report(Y_test,a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "[[199   0]\n",
      " [  9  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       199\n",
      "           1       1.00      0.53      0.69        19\n",
      "\n",
      "    accuracy                           0.96       218\n",
      "   macro avg       0.98      0.76      0.83       218\n",
      "weighted avg       0.96      0.96      0.95       218\n",
      "\n",
      "test kappa:- 0.6698081454055873\n",
      "test roc score 0.763157894736842\n"
     ]
    }
   ],
   "source": [
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_test_test = mdl.predict(x_testt)\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "print(confusion_matrix(y_testt,y_test_test))\n",
    "print(classification_report(y_testt,y_test_test))\n",
    "\n",
    "print('test kappa:-',cohen_kappa_score(y_testt, y_test_test))\n",
    "print('test roc score',roc_auc_score(y_testt, y_test_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Random Forest\n",
    "\n",
    "params:n_estimators=int(10.27),bootstrap = True, max_depth = 3, max_features = 8, max_leaf_nodes = 17, n_jobs = 9, random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  0.9774590163934426  Val AUC-ROC score:  0.8985001743983257 \n",
      "\n",
      "validation kappa:- 0.8184097421203438\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  0.9774590163934427  Val AUC-ROC score:  0.9434949424485525 \n",
      "\n",
      "validation kappa:- 0.8699221756606517\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  0.9692622950819672  Val AUC-ROC score:  0.9516916637600279 \n",
      "\n",
      "validation kappa:- 0.897513644633111\n",
      "[[118   4]\n",
      " [  3  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       122\n",
      "           1       0.92      0.94      0.93        47\n",
      "\n",
      "    accuracy                           0.96       169\n",
      "   macro avg       0.95      0.95      0.95       169\n",
      "weighted avg       0.96      0.96      0.96       169\n",
      "\n",
      "\n",
      "\n",
      "........................Testing the Model..............................\n",
      "\n",
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "Here we go with the confision Matrix\n",
      "\n",
      "[[199   0]\n",
      " [ 14   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       199\n",
      "           1       1.00      0.26      0.42        19\n",
      "\n",
      "    accuracy                           0.94       218\n",
      "   macro avg       0.97      0.63      0.69       218\n",
      "weighted avg       0.94      0.94      0.92       218\n",
      "\n",
      "test kappa: \t 0.3946846489488298\n",
      "test roc score: \t 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=int(10.27),bootstrap = True, max_depth = 3, max_features = 8, max_leaf_nodes = 17, n_jobs = 9, random_state = 42)\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "# X is the feature set and y is the target\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y): \n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    #print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "#     X_test, Y_test = sm.fit_sample(X_test, Y_test.ravel())\n",
    "    \n",
    "    \n",
    "    model = clf.fit(X_train,Y_train)\n",
    "    a_train = model.predict(X_train)\n",
    "    a_test = model.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "    print('validation kappa:-',cohen_kappa_score(Y_test,a_test))\n",
    "\n",
    "print(confusion_matrix(Y_test,a_test))\n",
    "print(classification_report(Y_test,a_test))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('........................Testing the Model..............................\\n')\n",
    "\n",
    "\n",
    "\n",
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_testt_pred = model.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.5:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "\n",
    "print('Here we go with the confision Matrix\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "\n",
    "print('test kappa: \\t',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score: \\t',roc_auc_score(y_testt, a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_KFOLD_OVERSAMPLING.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'random_forest_KFOLD_OVERSAMPLING.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. XGBOOST\n",
    "\n",
    "params: {\n",
    "    'min_child_weight': 10.0,\n",
    "    'lambda': 0.3397604475560514,\n",
    "    'objective': 'binary:logistic',\n",
    "    \n",
    "    'max_depth': 20,\n",
    "    'alpha': 5.7154910613882356e-05,\n",
    "    'max_delta_step': 0.1,\n",
    "    'eta': 0.1673343679061888,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.1673343679061888,\n",
    "    'gamma': 1.019025732933819e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "    'eval_metric' : 'auc',\n",
    "    'silent': 1,\n",
    "    'num_boost_round' : 700,\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/4]\n",
      "[12:30:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { num_boost_round, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.94343\tvalid-auc:0.81025\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 1000 rounds.\n",
      "[1000]\ttrain-auc:0.99980\tvalid-auc:0.96491\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-auc:0.99960\tvalid-auc:0.96646\n",
      "\n",
      "val kappa:- 0.8027950310559007\n",
      "[Fold 1/4 Prediciton:]\n",
      "[Fold 2/4]\n",
      "[12:30:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { num_boost_round, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.89963\tvalid-auc:0.88991\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 1000 rounds.\n",
      "[1000]\ttrain-auc:0.99764\tvalid-auc:0.99130\n",
      "Stopping. Best iteration:\n",
      "[190]\ttrain-auc:0.99711\tvalid-auc:0.99192\n",
      "\n",
      "val kappa:- 0.8968318440292445\n",
      "[Fold 1/4 Prediciton:]\n",
      "[Fold 3/4]\n",
      "[12:30:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { num_boost_round, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.97852\tvalid-auc:0.89896\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 1000 rounds.\n",
      "[1000]\ttrain-auc:0.99754\tvalid-auc:0.97863\n",
      "Stopping. Best iteration:\n",
      "[235]\ttrain-auc:0.99745\tvalid-auc:0.98046\n",
      "\n",
      "val kappa:- 0.7849776820070802\n",
      "[Fold 1/4 Prediciton:]\n",
      "[Fold 4/4]\n",
      "[12:31:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { num_boost_round, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.92364\tvalid-auc:0.86044\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 1000 rounds.\n",
      "[1000]\ttrain-auc:0.99773\tvalid-auc:0.99780\n",
      "Stopping. Best iteration:\n",
      "[139]\ttrain-auc:0.99552\tvalid-auc:0.99812\n",
      "\n",
      "val kappa:- 0.9222462203023758\n",
      "[Fold 1/4 Prediciton:]\n"
     ]
    }
   ],
   "source": [
    "kfold = 4\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'lambda': 0.3397604475560514,\n",
    "    'objective': 'binary:logistic',\n",
    "    \n",
    "    'max_depth': 20,\n",
    "    'alpha': 5.7154910613882356e-05,\n",
    "    'max_delta_step': 0.1,\n",
    "    'eta': 0.1673343679061888,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.1673343679061888,\n",
    "    'gamma': 1.019025732933819e-06,\n",
    "    'grow_policy': 'depthwise',\n",
    "    'eval_metric' : 'auc',\n",
    "    'silent': 1,\n",
    "    'num_boost_round' : 700,\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = x[train_index], x[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, y_train = sm.fit_sample(X_train, y_train.ravel())\n",
    "    \n",
    "    # Convert our data into XGBoost format\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    mdl = xgb.train(params, d_train, 30000, watchlist, early_stopping_rounds=1000, maximize=True,verbose_eval = 1000)\n",
    "    a_valid = mdl.predict(d_valid)\n",
    "    \n",
    "    a = []\n",
    "    for i in a_valid:\n",
    "        if i>0.6:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    \n",
    "    print('val kappa:-',cohen_kappa_score(y_valid, a))\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_KFOLD_OVERSAMPLING.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mdl, 'xgboost_KFOLD_OVERSAMPLING.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing on independent test data set using XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "[[199   0]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       199\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00       218\n",
      "   macro avg       1.00      1.00      1.00       218\n",
      "weighted avg       1.00      1.00      1.00       218\n",
      "\n",
      "test kappa:- 1.0\n",
      "test roc score 1.0\n"
     ]
    }
   ],
   "source": [
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "x_testt = xgb.DMatrix(np.array(x_testt),y_testt)\n",
    "y_testt_pred = mdl.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.6:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "print('test kappa:-',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score',roc_auc_score(y_testt, a_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. LGBM:\n",
    "\n",
    "params: iterations = 1000,\n",
    "    subsample=.8,\n",
    "    learning_rate=.1,\n",
    "    max_depth=10, max_delta_step = 0.1, alpha = 5.71, min_child_weight = 10, eta = 0.167, cosample_bytree = 0.4,\n",
    "    num_boost_round = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: cosample_bytree\n",
      "[LightGBM] [Warning] learning_rate is set=0.1, eta=0.167 will be ignored. Current value: learning_rate=0.1\n",
      "[LightGBM] [Warning] num_iterations is set=700, num_boost_round=700 will be ignored. Current value: num_iterations=700\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "K-FOLD # 1\n",
      "Train AUC-ROC Score:  0.9959016393442625  Val AUC-ROC score:  0.9197767701430066 \n",
      "\n",
      "validation kappa:- 0.850680332214172\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: cosample_bytree\n",
      "[LightGBM] [Warning] learning_rate is set=0.1, eta=0.167 will be ignored. Current value: learning_rate=0.1\n",
      "[LightGBM] [Warning] num_iterations is set=700, num_boost_round=700 will be ignored. Current value: num_iterations=700\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "K-FOLD # 2\n",
      "Train AUC-ROC Score:  0.9918032786885246  Val AUC-ROC score:  0.9475933031042901 \n",
      "\n",
      "validation kappa:- 0.883628851781718\n",
      "[LightGBM] [Warning] Unknown parameter: iterations\n",
      "[LightGBM] [Warning] Unknown parameter: cosample_bytree\n",
      "[LightGBM] [Warning] learning_rate is set=0.1, eta=0.167 will be ignored. Current value: learning_rate=0.1\n",
      "[LightGBM] [Warning] num_iterations is set=700, num_boost_round=700 will be ignored. Current value: num_iterations=700\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "K-FOLD # 3\n",
      "Train AUC-ROC Score:  0.9877049180327869  Val AUC-ROC score:  0.9475933031042901 \n",
      "\n",
      "validation kappa:- 0.883628851781718\n"
     ]
    }
   ],
   "source": [
    "kfold = 3\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "clf = lgb.LGBMClassifier(iterations = 1000,\n",
    "    subsample=.8,\n",
    "    learning_rate=.1,\n",
    "    max_depth=10, max_delta_step = 0.1, alpha = 5.71, min_child_weight = 10, eta = 0.167, cosample_bytree = 0.4,\n",
    "    num_boost_round = 700)\n",
    "fold = 1\n",
    "for train_index, val_index in skf.split(x,y):\n",
    "#     x, y = sm.fit_sample(x, y.ravel())\n",
    "    #print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = x[train_index], x[val_index] \n",
    "    Y_train, Y_test = y[train_index], y[val_index]\n",
    "    \n",
    "    X_train, Y_train = sm.fit_sample(X_train, Y_train.ravel())\n",
    "    \n",
    "    mdl = clf.fit(X_train,Y_train)\n",
    "    a_train = mdl.predict(X_train)\n",
    "    a_test = mdl.predict(X_test)\n",
    "    print('K-FOLD #',fold)\n",
    "    fold+=1\n",
    "    print('Train AUC-ROC Score: ',roc_auc_score(Y_train,a_train),' Val AUC-ROC score: ',roc_auc_score(Y_test,a_test),'\\n')\n",
    "    print('validation kappa:-',cohen_kappa_score(Y_test,a_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBM_KFOLDOVERSAMPLING.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mdl, 'LGBM_KFOLDOVERSAMPLING.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LGBM on independent test data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:- NSCLC Detected \t& \t1:- Normal\n",
      "\n",
      "[[197   2]\n",
      " [  0  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       199\n",
      "           1       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.99       218\n",
      "   macro avg       0.95      0.99      0.97       218\n",
      "weighted avg       0.99      0.99      0.99       218\n",
      "\n",
      "test kappa:- 0.944963393082555\n",
      "test roc score 0.9949748743718593\n"
     ]
    }
   ],
   "source": [
    "y_testt = test['Disease Status (NSCLC: primary tumors; Normal: non-tumor lung tissues)']\n",
    "x_testt = test[test.columns[:-1]]\n",
    "y_testt_pred = mdl.predict(x_testt)\n",
    "\n",
    "a_test = []\n",
    "for i in y_testt_pred:\n",
    "    if i>0.6:\n",
    "        a_test.append(1)\n",
    "    else:\n",
    "        a_test.append(0)\n",
    "print('0:- NSCLC Detected', '\\t& \\t1:- Normal\\n')\n",
    "print(confusion_matrix(y_testt,a_test))\n",
    "print(classification_report(y_testt,a_test))\n",
    "print('test kappa:-',cohen_kappa_score(y_testt, a_test))\n",
    "print('test roc score',roc_auc_score(y_testt, a_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
